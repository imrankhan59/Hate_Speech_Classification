# Hate Speech Classification

This project focuses on automatically detecting hate speech and offensive language in social media text using machine learning. The goal is to build a system that can identify harmful or abusive content to help maintain a safer online environment.

The project covers the complete end-to-end machine learning workflow â€” from data collection and preprocessing to model training, experiment tracking, and deployment. It integrates modern MLOps tools like **MLflow** for experiment tracking, **DVC** for data and model versioning, and **FastAPI** for serving the trained model as an API.

By combining natural language processing (NLP) techniques and machine learning algorithms, this project provides an efficient pipeline to classify text into categories such as *Hate Speech*, *Offensive Language*, or *Neutral*.



## Problem Statement

Social media platforms receive millions of comments and posts every day. Among them, some contain hate speech or offensive language that can harm individuals or communities. Manually monitoring and filtering such content is not practical due to the large volume of data.

This project aims to build an automated machine learning model that can detect and classify text as **Hate Speech**, **Offensive Language**, or **Neutral**. The goal is to support content moderation systems by accurately identifying harmful language and helping create a safer online space.



##  Project Architecture

The project follows a complete end-to-end machine learning workflow. It starts with collecting and cleaning the data, then moves on to training and evaluating the model. After that, the model is tracked, versioned, and finally deployed using modern MLOps tools.

Below is a simple view of the pipeline:

1. **Data Collection:** Gather hate speech and offensive language data.
2. **Data Preprocessing:** Clean and prepare text for modeling.
3. **Model Training:** Train machine learning models on the processed data.
4. **Model Evaluation:** Check how well the model performs using metrics like F1-score.
5. **Experiment Tracking:** Use MLflow to track experiments and results.
6. **Version Control:** Use DVC to manage datasets and model versions.
7. **Deployment:** Deploy the final model using FastAPI for real-time predictions.

This setup makes the workflow easy to reproduce, monitor, and improve over time.

##  Model and Techniques Used

The project uses natural language processing (NLP) and machine learning to classify text. Hereâ€™s what we do:

- **Text Preprocessing:** Clean the text by removing unnecessary characters, converting to lowercase, and removing stopwords.
- **Feature Extraction:** Convert text into numbers that the model can understand, using techniques like word2vec.
- **Model:** Train a machine learning model (e.g., RNN/LSTM) on the processed text.
- **Evaluation:** Measure the model's performance using metrics like F1-score, Precision, and Recall to make sure it correctly identifies hate speech and offensive language.


## ğŸ“ Project Structure

Hereâ€™s how the project files and folders are organized:

â”‚
â”œâ”€â”€ data/ # Raw and processed data (created during data ingestion)
â”œâ”€â”€ artifacts/ # Stores intermediate outputs like validation reports, transformed data, and trained models
â”œâ”€â”€ src/ # Source code for all components
â”‚ â”œâ”€â”€ components/ # Data ingestion, transformation, model training, and evaluation modules
â”‚ â”œâ”€â”€ configuration/ # Configuration files (e.g., DB connections)
â”‚ â”œâ”€â”€ constant/ # Constants used across the project
â”‚ â”œâ”€â”€ entity/ # Data classes for configuration and artifacts
â”‚ â”œâ”€â”€ exception/ # Custom exception handling
â”‚ â”œâ”€â”€ logger/ # Logging setup
â”‚ â”œâ”€â”€ pipeline/ # Training and prediction pipelines
â”‚ â”œâ”€â”€ ml/ # Model definitions
â”‚ â””â”€â”€ utils/ # Utility functions
â”‚
â”œâ”€â”€ tests/ # Unit and integration tests
â”‚ â”œâ”€â”€ unit/
â”‚ â””â”€â”€ integration/
â”‚
â”œâ”€â”€ experiments/ # Jupyter notebooks for experiments
â”œâ”€â”€ .github/workflows/ # GitHub Actions workflows
â”œâ”€â”€ Dockerfile # Docker configuration
â”œâ”€â”€ app.py # FastAPI application for deployment
â”œâ”€â”€ demo.py # Script for testing or demoing the model
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ requirements_dev.txt # Dev dependencies (testing, linting)
â”œâ”€â”€ setup.py # Optional packaging setup
â”œâ”€â”€ dvc.yaml # DVC pipeline configuration
â”œâ”€â”€ params.yaml # Parameters for pipeline stages
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ .gitignore # Files/folders to ignore in Git
â””â”€â”€ .env # Environment variables